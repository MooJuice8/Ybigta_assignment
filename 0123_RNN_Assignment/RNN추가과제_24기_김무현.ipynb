{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmJ-t9b50PiK"
      },
      "source": [
        "##Text Generation using RNN LSTM (Pytorch)\n",
        "###Lyrics generatator  \n",
        "ü§ñ LSTM, GRUÏóê ÎåÄÌï¥ ÌïúÍµ≠Ïñ¥Î°ú Îçî Ïûò ÏïåÍ≥† Ïã∂Îã§Î©¥  \n",
        "https://velog.io/@hipjaengyi_cat18/RNNRecurrent-Neural-NetworkÍ≥º-LSTM-GPUÎ•º-Ïù¥Ìï¥Ìï¥Î≥¥Ïûê-ÎÇ¥Í∞ÄÎ≥¥Î†§Í≥†Ï†ïÎ¶¨ÌïúAI  \n",
        "ü§ñ Ï∞∏Í≥†Ìïú ÏΩîÎìú  \n",
        "https://github.com/trekhleb/machine-learning-experiments/tree/0cfc7cac2daaff3e37b33bbf1284d3f19a5d78a1/experiments/text_generation_shakespeare_rnn   \n",
        "https://www.kaggle.com/code/super13579/let-s-auto-write-the-deep-purple-lysics-pytorch/notebook#Let's-use-the-Deep-Purple-lysics-to-train-a-LSTM-simulated-Deep-Purple-write-lyrics-automatically-(Rock!!)   \n",
        "& special thanks to DS 22Í∏∞ Ï°∞ÏÑ±Ïõê  \n",
        "ü§ñ Îç∞Ïù¥ÌÑ∞ÏÖã   \n",
        "from kaggle  \n",
        "ü§ñ LSTM ÎÖºÎ¨∏  \n",
        "https://www.bioinf.jku.at/publications/older/2604.pdf  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPRHPzB089b"
      },
      "source": [
        "##I. INTRODUCTION  \n",
        "Implementing a Recurrent Neural Network (RNN), specifically Long-Short Term Memory (LSTM), to create a lyrics generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQPMObZT1Cvw"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aUafOKUy1Ezw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MoohyeonKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform\n",
        "import time\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjSB9AyB1Imb"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dt9XuA_1KLX"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_i-KTLK21M8x"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>artist</th>\n",
              "      <th>seq</th>\n",
              "      <th>song</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
              "      <td>Everyday</td>\n",
              "      <td>0.626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
              "      <td>Live Till We Die</td>\n",
              "      <td>0.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
              "      <td>The Otherside</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
              "      <td>Pinot</td>\n",
              "      <td>0.536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>I see a midnight panther, so gallant and so br...</td>\n",
              "      <td>Shadows &amp; Diamonds</td>\n",
              "      <td>0.371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        artist  \\\n",
              "0           0  Elijah Blake   \n",
              "1           1  Elijah Blake   \n",
              "2           2  Elijah Blake   \n",
              "3           3  Elijah Blake   \n",
              "4           4  Elijah Blake   \n",
              "\n",
              "                                                 seq                song  \\\n",
              "0  No, no\\r\\nI ain't ever trapped out the bando\\r...            Everyday   \n",
              "1  The drinks go down and smoke goes up, I feel m...    Live Till We Die   \n",
              "2  She don't live on planet Earth no more\\r\\nShe ...       The Otherside   \n",
              "3  Trippin' off that Grigio, mobbin', lights low\\...               Pinot   \n",
              "4  I see a midnight panther, so gallant and so br...  Shadows & Diamonds   \n",
              "\n",
              "   label  \n",
              "0  0.626  \n",
              "1  0.630  \n",
              "2  0.240  \n",
              "3  0.536  \n",
              "4  0.371  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ÎìúÎùºÏù¥Î∏åÏóê ÏûàÎäî CSV ÌååÏùº ÏùΩÍ∏∞ ÏòàÏãú (lyrics.csvÍ∞Ä ÏûàÎäî ÌååÏùº Í≤ΩÎ°úÎ•º Ï†ÅÏñ¥Ï£ºÏÑ∏Ïöî)\n",
        "#file_path = '/content/drive/MyDrive/ÌååÏùºÍ≤ΩÎ°ú../lyrics.csv'\n",
        "#df = pd.read_csv(file_path)\n",
        "df = pd.read_csv('lyrics.csv')\n",
        "# data frame ÌôïÏù∏\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b5Rbh1er1eUG"
      },
      "outputs": [],
      "source": [
        "#Îç∞Ïù¥ÌÑ∞ Ï§ë ÏùºÎ∂ÄÎßå Í∞ÄÏ†∏Ïò§Í∏∞ - Í∞ÄÏ†∏Ïò¨ Îç∞Ïù¥ÌÑ∞ ÏûêÏú†Î°≠Í≤å ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî\n",
        "random_sample = df.sample(n=1000, random_state=19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gRPn3gdD1gbP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0              artist  \\\n",
            "67830        67830             Darkane   \n",
            "114589      114589              Kemuri   \n",
            "111513      111513                Them   \n",
            "98856        98856  Hank Williams, Jr.   \n",
            "23427        23427   The Panic Channel   \n",
            "\n",
            "                                                      seq  \\\n",
            "67830   The beauty of your escaping soul\\r\\nBehold my ...   \n",
            "114589  Are we still the same?\\r\\nOr are we so differe...   \n",
            "111513  Well, I love you, love you darlin'\\r\\nLike I n...   \n",
            "98856   Mr Weather man what is your forecast,\\r\\nI nee...   \n",
            "23427   I'm silent\\r\\nIn the rolling wake\\r\\nOf lucky ...   \n",
            "\n",
            "                       song   label  \n",
            "67830   Chase for Existence  0.0614  \n",
            "114589        Second Chance  0.8120  \n",
            "111513       All for Myself  0.8080  \n",
            "98856            Weatherman  0.3630  \n",
            "23427              Outsider  0.1650  \n"
          ]
        }
      ],
      "source": [
        "#Í∞ÄÏ†∏Ïò® Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏\n",
        "print(random_sample.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vow1djLS1ln9"
      },
      "source": [
        "##Analyze the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4fAjivU91r5U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the beauty of your escaping soul\n",
            "behold my true distress\n",
            "your naked mind is barely existing\n",
            "corpus length: 1143721\n"
          ]
        }
      ],
      "source": [
        "#Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑÏóêÏÑú 'seq' Ïó¥(Í∞ÄÏÇ¨Î∂ÄÎ∂Ñ)ÏùÑ ÏÑ†ÌÉùÌïòÍ≥†, Í∞Å ÌñâÏùò 'seq' Í∞íÏùÑ ÏÜåÎ¨∏ÏûêÎ°ú Î≥ÄÌôò\n",
        "random_text = random_sample['seq'].str.cat(sep='\\n').lower()\n",
        "print(random_text[:94])\n",
        "print('corpus length:', len(random_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jF-v-1nQ1t02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the beauty of your escaping soul\n",
            "behold my true distress\n",
            "your naked mind is barely existing\n",
            "i have dreams you could never imagine\n",
            "explore your forbidden defiance\n",
            "see the realm of temptation\n",
            "knowing anger\n",
            "will betray me\n",
            "disconnected\n",
            "from all feelings\n",
            "the chase for my existence\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 286 characters in text.\n",
        "print(random_text[:286])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bzsxEKR71xR1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63 unique characters\n",
            "vocab: ['\\t', '\\n', '\\r', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '>', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file ÌôïÏù∏\n",
        "vocab = sorted(set(random_text))\n",
        "\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "print('vocab:', vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q69DoyMY11if"
      },
      "source": [
        "##Process the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkyU5yF16Bw"
      },
      "source": [
        "###Vectorize the text\n",
        "Recurrent Neural Network (RNN)Ïóê ÌÖçÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î•º ÏûÖÎ†•ÏúºÎ°ú Ï†úÍ≥µÌïòÍ∏∞ Ï†ÑÏóê, ÌÖçÏä§Ìä∏Î•º Î¨∏ÏûêÏùò ÏãúÌÄÄÏä§ÏóêÏÑú Ïà´ÏûêÏùò ÏãúÌÄÄÏä§Î°ú Î≥ÄÌôòÌïòÎäî Í≥ºÏ†ïÏùÑ Í±∞Ïπ©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I8a2MQBL14tm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\t':   0,\n",
            "  '\\n':   1,\n",
            "  '\\r':   2,\n",
            "  ' ' :   3,\n",
            "  '!' :   4,\n",
            "  '\"' :   5,\n",
            "  '#' :   6,\n",
            "  '%' :   7,\n",
            "  '&' :   8,\n",
            "  \"'\" :   9,\n",
            "  '(' :  10,\n",
            "  ')' :  11,\n",
            "  '*' :  12,\n",
            "  '+' :  13,\n",
            "  ',' :  14,\n",
            "  '-' :  15,\n",
            "  '.' :  16,\n",
            "  '/' :  17,\n",
            "  '0' :  18,\n",
            "  '1' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "char2index = {char: index for index, char in enumerate(vocab)}\n",
        "\n",
        "print('{')\n",
        "for char, _ in zip(char2index, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2index[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2O3TA1Bq2BF5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\t' '\\n' '\\r' ' ' '!' '\"' '#' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.'\n",
            " '/' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '>' '?' '[' ']' '`'\n",
            " 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '{' '}']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Map character indices to characters from vacabulary.\n",
        "index2char = np.array(vocab)\n",
        "print(index2char)\n",
        "\n",
        "len(index2char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nSFDK8un2EQg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text_as_int length: 1143721\n",
            "'the beauty of your escaping soul' --> array([54, 42, 39,  3, 36, 39, 35, 55, 54, 59,  3, 49, 40,  3, 59, 49, 55,\n",
            "       52,  3, 39, 53, 37, 35, 50, 43, 48, 41,  3, 53, 49, 55, 46])\n"
          ]
        }
      ],
      "source": [
        "# Convert chars in text to indices.\n",
        "text_as_int = np.array([char2index[char] for char in random_text])\n",
        "\n",
        "print('text_as_int length: {}'.format(len(text_as_int)))\n",
        "print('{} --> {}'.format(repr(random_text[:32]), repr(text_as_int[:32])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQVux07S2LlN"
      },
      "source": [
        "## Create training sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nmSyEX0F2OG2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Window\n",
            "['the beauty of your escaping soul\\r\\nbehold my true d', 'he beauty of your escaping soul\\r\\nbehold my true di', 'e beauty of your escaping soul\\r\\nbehold my true dis', ' beauty of your escaping soul\\r\\nbehold my true dist', 'beauty of your escaping soul\\r\\nbehold my true distr']\n",
            "Target charaters\n",
            "['i' 's' 't' 'r' 'e']\n",
            "Number of sequences: 1143671\n"
          ]
        }
      ],
      "source": [
        "seq_length = 50\n",
        "step = 1\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(random_text) - seq_length, step):\n",
        "  sentences.append(random_text[i:i+seq_length])\n",
        "  next_chars.append(random_text[i+seq_length]) #Next character\n",
        "\n",
        "senteces = np.array(sentences)\n",
        "next_chars= np.array(next_chars)\n",
        "\n",
        "\n",
        "#Print Sentence Window and next charaters\n",
        "print('Sentence Window')\n",
        "print (sentences[:5])\n",
        "print('Target charaters')\n",
        "print (next_chars[:5])\n",
        "print('Number of sequences:', len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i9OxqoOQ2Sq_"
      },
      "outputs": [],
      "source": [
        "def getdata(sentences, next_chars):\n",
        "    X = np.zeros((len(sentences),seq_length))\n",
        "    y = np.zeros((len(sentences)))\n",
        "    length = len(sentences)\n",
        "    index = 0\n",
        "    for i in range(len(sentences)):\n",
        "        sentence = sentences[i]\n",
        "        for t, char in enumerate(sentence):\n",
        "            X[i, t] = char2index[char]\n",
        "        y[i] = char2index[next_chars[i]]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V1F2Nb9b2UlX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training_x: (1143671, 50)\n",
            "Shape of training_y: (1143671,)\n"
          ]
        }
      ],
      "source": [
        "train_x,train_y = getdata(sentences, next_chars)\n",
        "print('Shape of training_x:', train_x.shape)\n",
        "print('Shape of training_y:', train_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYsqkk1Z2aMT"
      },
      "source": [
        "##Build the Model(Pytorch)\n",
        "## Ï∂îÍ≥º Í≥ºÏ†ú 1 : ÏïÑÎûò Îπà Í≥≥ÏùÑ Ï±ÑÏõåÏ£ºÏÑ∏Ïöî!\n",
        "- Embedding layer : transfer index to embedding vector\n",
        "- Simple LSTM + dropout : Sequence data to hidden states , dropout for prevent overfitting\n",
        "- Fully connection layer : linear tranfer to a n_vocab vector to be output layer.  \n",
        "we don't need to do softmax here, we will do it when we calculate loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9-izwsvq2bMS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Simple_LSTM(nn.Module):\n",
        "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
        "        super(Simple_LSTM, self).__init__()\n",
        "        ##################################################################\n",
        "        # TODO: Ï£ºÏÑù, ________ Î∂ÄÎ∂Ñ ÏßÄÏö∞Í≥† ÎãµÏïà ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.\n",
        "        #\n",
        "        # Hint: ÏúÑÏóê embedding layer, simple LSTM + dropout, fully connected layer ÏÑ§Î™Ö Î∂ÄÎ∂ÑÏùÑ ÏùΩÍ≥† Ï±ÑÏõåÏ£ºÏãúÎ©¥ Îê©ÎãàÎã§.\n",
        "        #\n",
        "        ##################################################################\n",
        "        # ÏïÑÎûò Ï£ºÏÑù Ìï¥Ï†ú ÌõÑ Ï†ïÏùòÌï¥Ï£ºÏÑ∏Ïöî.\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim \n",
        "        self.lstm = nn.LSTM(hidden_dim, embedding_dim, dropout = dropout, num_layers = 2)\n",
        "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
        "        ##################################################################\n",
        "        #                         END OF YOUR CODE                       #\n",
        "        ##################################################################\n",
        "\n",
        "    def forward(self, seq_in):\n",
        "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
        "        embedded = self.embeddings(seq_in.t())\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        # Only need to keep the last character\n",
        "        ht=lstm_out[-1]\n",
        "        out = self.fc(ht)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsBNZmn72has"
      },
      "source": [
        "## Create DataLoader of mini-batch training\n",
        "Use GPU to training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oxniKXkX2kMY"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mcuda()\n",
            "File \u001b[1;32mc:\\Users\\MoohyeonKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
            "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "X_train_tensor = torch.tensor(train_x, dtype=torch.long).cuda()\n",
        "Y_train_tensor = torch.tensor(train_y, dtype=torch.long).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHQTDkkI2m_X"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = 32) #batch_size ÏûêÏú†Î°≠Í≤å Î∞îÍøîÏ£ºÏÑ∏Ïöî"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39856I6b2rna"
      },
      "source": [
        "##Start training\n",
        "- Hidden_size : 256\n",
        "- Embedding_size : 256\n",
        "- Use Adam optimizer(Î≥ÄÍ≤Ω Í∞ÄÎä•)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lctdA0O52tYl"
      },
      "outputs": [],
      "source": [
        "model = Simple_LSTM(63,256,256)\n",
        "model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # optimizer ÏûêÏú†Î°≠Í≤å Î∞îÍøîÏ£ºÏÑ∏Ïöî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCyrqWdB21Cf"
      },
      "outputs": [],
      "source": [
        "import time # Add time counter\n",
        "avg_losses_f = []\n",
        "n_epochs=10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    avg_loss = 0.\n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        y_pred = model(x_batch)\n",
        "\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        avg_loss+= loss.item()/len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "\n",
        "    avg_losses_f.append(avg_loss)\n",
        "\n",
        "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Na3v8B3L2Q"
      },
      "source": [
        "##Í≤∞Í≥º ÎèÑÏãùÌôî"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIJh9gNm3M3e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(avg_losses_f)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPqcB6qq3WhR"
      },
      "source": [
        "##Create the function that can sample an index from a probability array\n",
        "- This function is to prevent the most likely chracter always be chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNTk5dkY3XV5"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O37RYi4v3a_c"
      },
      "source": [
        "## Validate the model\n",
        "- Define the 50 start sentence legth (ÏïûÏóê seq_lenth Î∞îÍæ∏Î©¥ sentence length Î∞îÍæ∏Í∏∞ Í∞ÄÎä•)\n",
        "- Predict next char\n",
        "- Total create 400 characters lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsCmCcii3iJB"
      },
      "outputs": [],
      "source": [
        "# Define the start sentence\n",
        "sentence = 'i read in the book\\nthat the joyful man\\nplease kno'\n",
        "variance = 0.25\n",
        "generated = ''\n",
        "original = sentence\n",
        "window = sentence\n",
        "\n",
        "for i in range(400):\n",
        "    x = np.zeros((1, seq_length))\n",
        "    for t, char in enumerate(window):\n",
        "        x[0, t] = char2index[char] # Change the sentence to index vector shape (1,50)\n",
        "\n",
        "    x_in = Variable(torch.LongTensor(x).cuda())\n",
        "    pred = model(x_in)\n",
        "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
        "    next_index = sample(pred, variance)\n",
        "    next_char = index2char[next_index] # index to char\n",
        "\n",
        "    generated += next_char\n",
        "    window = window[1:] + next_char # Update Window for next char predict\n",
        "\n",
        "print(original + generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI5iJ0qr9nFd"
      },
      "source": [
        "Ï∂îÍ∞ÄÍ≥ºÏ†ú -2\n",
        "## PytorchÎ°ú RNN Íµ¨ÌòÑÌï¥Î≥¥Í∏∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smp0bv5T9KDV"
      },
      "source": [
        "## 1. RNN Íµ¨ÌòÑ\n",
        "PytorchÎ°ú neural network Î™®Îç∏ÏùÑ Íµ¨ÌòÑÌï† ÎïåÏóêÎäî `nn.Module`ÏùÑ ÏÉÅÏÜçÎ∞õÏïÑÏÑú Íµ¨ÌòÑÌïòÍ≤å Îê©ÎãàÎã§.\n",
        "\n",
        "### [Ï∞∏Í≥†] Í∞ùÏ≤¥ÏßÄÌñ• Í∞úÎÖêÏùÑ Ïûò Î™®Î•∏Îã§Î©¥?\n",
        "Í∞ùÏ≤¥ÏßÄÌñ• Í∞úÎÖêÏùÑ Ïûò Î™®Î•¥Ïã†Îã§Î©¥ <b>ÏÉÅÏÜç</b>Ïù¥ÎûÄ ÏÉÅÏÜçÏùÑ Î∞õÏùÄ ÌÅ¥ÎûòÏä§ (Ïó¨Í∏∞ÏÑúÎäî CustomRNN)Í∞Ä Î∂ÄÎ™® ÌÅ¥ÎûòÏä§ (`nn.Module`)Ïùò Î©§Î≤Ñ Î≥ÄÏàòÏôÄ Î©îÏÜåÎìúÎ•º Í∑∏ÎåÄÎ°ú ÎÑòÍ≤®Î∞õÏïÑ ÌïÑÏöîÏóê ÎßûÍ≤å Ïû¨Ï†ïÏùòÌïòÍ±∞ÎÇò Í∏∞ÌÉÄ ÌïÑÏöîÌïú Í∏∞Îä•Îì§ÏùÑ Ï∂îÍ∞ÄÌï¥ÏÑú ÏÇ¨Ïö©ÌïòÎäî ÌñâÏúÑÎ°ú ÏâΩÍ≤å Ïù¥Ìï¥ÌïòÏãúÎ©¥ Îê©ÎãàÎã§. Ïù¥Î•º ÌÜµÌï¥ ÏΩîÎìúÏùò Ï§ëÎ≥µÎèÑÎ•º ÎÇÆÏ∂îÍ≥† Î≥¥Îã§ Ìö®Ïú®Ï†ÅÏù∏ ÏÑ§Í≥ÑÎ•º Ìï† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "ÏòàÎ•º Îì§Ïñ¥ÏÑú `nn.Module` ÌÅ¥ÎûòÏä§Î•º ÏÉÅÏÜçÎ∞õÏïÑ ÎßåÎì† Î™®Îì† ÌÅ¥ÎûòÏä§Îì§ÏùÄ `__init()__` ÏÉùÏÑ±ÏûêÏôÄ `forward()` Î©îÏÜåÎìúÎ•º Íµ¨ÌòÑÌï®ÏúºÎ°úÏç® Î™®Îì† neural networkÍ∞Ä high levelÏóêÏÑúÎäî ÎèôÏùºÌïú ÎèôÏûëÏùÑ Ìï®ÏùÑ Î≥¥Ïû•Ìï† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "ÎßåÏïΩ ÏÉÅÏÜç Í∏∞Îä•ÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÎäîÎã§Î©¥ Î™®Îç∏ÏùÑ trainingÌïòÎäî ÏΩîÎìú, inferenceÎ•º ÌïòÎäî ÏΩîÎìú Îì±ÏùÑ neural network Ï¢ÖÎ•òÎßàÎã§ ÏÉàÎ°ú ÏßúÏïº ÌïòÎØÄÎ°ú Î≥µÏû°Ìï¥ÏßëÎãàÎã§.\n",
        "\n",
        "### Íµ¨ÌòÑ Í¥ÄÎ†® Î∞∞Í≤ΩÏßÄÏãù\n",
        "`nn.Module` ÌÅ¥ÎûòÏä§Î•º ÏÉÅÏÜçÎ∞õÏúºÎ©¥ `__init__()` ÏÉùÏÑ±ÏûêÏôÄ `forward()` Î©îÏÜåÎìúÎ•º Íµ¨ÌòÑÌï¥Ïïº Ìï©ÎãàÎã§. ÏÉùÏÑ±ÏûêÏóêÏÑúÎäî Î™®Îç∏ÏóêÏÑú ÏÇ¨Ïö©Ìï† Í∏∞Î≥∏Ï†ÅÏù∏ Î©§Î≤Ñ Î≥ÄÏàòÎì§ÏùÑ Ï¥àÍ∏∞ÌôîÌïòÍ≤å Îê©ÎãàÎã§. Ïó¨Í∏∞ÏÑú Î©§Î≤Ñ Î≥ÄÏàòÎ°úÎäî ÌÅ¨Í≤å Îëê Í∞ÄÏßÄÍ∞Ä ÏûàÏäµÎãàÎã§.\n",
        "1. Î™®Îç∏ ÏïÑÌÇ§ÌÖçÏ≥êÏôÄ Í¥ÄÎ†®Îêú dimensionÎì§ (Í∞ÅÍ∞ÅÏùò ÏùòÎØ∏Îäî Î∞úÏ†ú PPT Ï∞∏Í≥†)\n",
        " - Input vectorÏùò Í∏∏Ïù¥\n",
        " - Hidden layerÏùò Í∏∏Ïù¥\n",
        " - Output vectorÏùò Í∏∏Ïù¥\n",
        " - Batch size\n",
        "\n",
        "\n",
        "2. Î™®Îç∏ÏóêÏÑú ÏÇ¨Ïö©Îê† layerÎì§\n",
        " - PytorchÏùò `nn` moduleÏóêÏÑúÎäî neural networkÏóêÏÑú ÏÇ¨Ïö©ÎêòÎäî Îã§ÏñëÌïú layerÎ•º ÎØ∏Î¶¨ Íµ¨ÌòÑÌï¥ ÎëêÏóàÏäµÎãàÎã§. Convolution layer, pooling layer, linear layer Îì±Ïù¥ Ï†ïÏùòÎêòÏñ¥ ÏûàÏñ¥ÏÑú Î≥µÏû°Ìïú Ïó∞ÏÇ∞ÏùÑ ÏßÅÏ†ë Íµ¨ÌòÑÌï† ÌïÑÏöîÍ∞Ä ÏóÜÏäµÎãàÎã§. Î≥∏ Í≥ºÏ†úÏóêÏÑúÎäî Ìï¥Îãπ layerÎ•º ÏåìÏïÑÏÑú RNNÏùÑ Íµ¨ÌòÑÌïúÎã§Í≥† Î≥¥ÏãúÎ©¥ Îê©ÎãàÎã§.\n",
        " - Î≥∏ Í≥ºÏ†úÏóêÏÑúÎäî Linear layerÎßå ÌôúÏö©ÌïòÎ©¥ Îê©ÎãàÎã§. Ïù¥Îäî MLP ÏÑ∏ÏÖòÏóêÏÑú Î∞∞Ïö¥ fully connected layerÏôÄ Í∞ôÏäµÎãàÎã§. FC layerÏù¥ÎØÄÎ°ú input, outputÏùò sizeÏôÄ bias ÏÇ¨Ïö© Ïú†Î¨¥Îßå Ï†ïÏùòÌï¥Ï£ºÎ©¥ Îê©ÎãàÎã§. https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "\n",
        "ÏÉùÏÑ±ÏûêÎ•º Ï†ïÏùòÌñàÏúºÎ©¥ `forward()` Ìï®ÏàòÎ•º Ï†ïÏùòÌï† Ï∞®Î°ÄÏûÖÎãàÎã§. `forward()` Î©îÏÜåÎìúÍ∞Ä Î™®Îç∏ Íµ¨ÌòÑÏóêÏÑú ÌïµÏã¨ÏûÖÎãàÎã§. Ïù¥ Î©îÏÜåÎìúÎäî Î™®Îç∏Ïóê input dataÎ•º ÏßëÏñ¥ÎÑ£ÏúºÎ©¥ ÏûêÎèôÏúºÎ°ú Ìò∏Ï∂úÎêòÍ≥† argumentÎ°ú inputÏù¥ Ï†ÑÎã¨Îê©ÎãàÎã§. ÏïûÏÑú Ï†ïÏùòÌïú layerÎì§ÏùÑ Ïûò Ìò∏Ï∂úÌï¥ÏÑú Î©îÏÜåÎìúÎ•º Íµ¨ÌòÑÌïòÏãúÎ©¥ Îê©ÎãàÎã§.\n",
        "\n",
        "\n",
        "*Backward passÎäî Î™®Îç∏ trainÏùÑ Ìï† Îïå `backward()`Í∞Ä ÏïåÏïÑÏÑú Ìï¥Ï£ºÍ∏∞ ÎïåÎ¨∏Ïóê `forward()`Îßå Ï†ïÏùòÌïòÎäî Í≤ÉÏûÖÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dDbl35zl95nQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N2YsSoYG98Lh"
      },
      "outputs": [],
      "source": [
        "# nn.ModuleÏùÑ ÏÉÅÏÜçÎ∞õÏïÑÏÑú CustomRNN class Ï†ïÏùò\n",
        "\n",
        "class CustomRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN basic block\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        input_size: Input vector Í∏∏Ïù¥\n",
        "        hidden_size: Hidden state vector Í∏∏Ïù¥\n",
        "        output_size: Output vector Í∏∏Ïù¥\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.W_xh = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        ##################################################################\n",
        "        # TODO: ÌïÑÏöîÌïú Î©§Î≤Ñ Î≥ÄÏàò 2Í∞úÎ•º Ï∂îÍ∞ÄÎ°ú Ï†ïÏùòÌïòÏÑ∏Ïöî.\n",
        "        #\n",
        "        # 1. W_hh: hidden layer vectorÏóê Í≥±Ìï¥ÏßÄÎäî weight\n",
        "        # 2. W_hy: hidden layerÎ°ú outputÏùÑ ÏÉùÏÑ±Ìï† Îïå Í≥±Ìï¥ÏßÄÎäî weight\n",
        "        #\n",
        "        # Hint: ÏúÑÏùò self.W_xh ÏΩîÎìúÎ•º Ï∞∏Í≥†ÌïòÏÑ∏Ïöî.\n",
        "        #\n",
        "        ##################################################################\n",
        "        # ÏïÑÎûò Ï£ºÏÑù Ìï¥Ï†ú ÌõÑ Ï†ïÏùòÌïòÏãúÎ©¥ Îê©ÎãàÎã§. biasÎäî Îëò Îã§ TrueÎ°ú Ìï¥Ï£ºÏÑ∏Ïöî.\n",
        "        self.W_hh = nn.Linear(hidden_size, hidden_size, bias=True)  \n",
        "        self.W_hy = nn.Linear(hidden_size, output_size, bias=True)\n",
        "        ##################################################################\n",
        "        #                         END OF YOUR CODE                       #\n",
        "        ##################################################################\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        W_xh_x = self.W_xh(x)  # W_xh weightÏóê input xÎ•º Í≥±Ìï¥Ï§Ä Í≤∞Í≥º\n",
        "        ##################################################################\n",
        "        # TODO: Forward passÎ•º Í≥ÑÏÇ∞ÌïòÎäî ÏΩîÎìúÎ•º Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.\n",
        "        #\n",
        "        ########################### Ï†ÑÏ≤¥ Í≥ºÏ†ï ##############################\n",
        "        #\n",
        "        # 1. W_xhÏôÄ inputÏùÑ Í≥±ÌïúÎã§.\n",
        "        # 2. W_hhÏôÄ {t - 1} ÏãúÏ†êÏóêÏÑúÏùò hidden state vectorÎ•º Í≥±ÌïúÎã§.\n",
        "        # 3. ÎëòÏù¥ ÎçîÌïúÎã§.\n",
        "        # 4. tanhÎ•º ÌÜµÍ≥ºÏãúÏºúÏÑú ÏÉàÎ°úÏö¥ hidden stateÎ•º ÎßåÎì§Ïñ¥ÎÇ∏Îã§.\n",
        "        # 5. W_hyÏôÄ ÏÉàÎ°úÏö¥ hidden stateÎ•º Í≥±Ìï¥ÏÑú outputÏùÑ ÎßåÎì§Ïñ¥ÎÇ∏Îã§.\n",
        "        # 6. outputÍ≥º ÏÉàÎ°úÏö¥ hidden stateÎ•º returnÌïúÎã§.\n",
        "        #\n",
        "        # Hint: torch.tanh\n",
        "        #\n",
        "        ##################################################################\n",
        "        # ÏïÑÎûò Ï£ºÏÑù Ìï¥Ï†ú ÌõÑ Ï∂îÍ∞ÄÌïòÏãúÎ©¥ Îê©ÎãàÎã§.\n",
        "        W_hh_x = self.W_hh(hidden_state)\n",
        "        hidden_state = torch.tanh(W_xh_x + W_hh_x)\n",
        "        output = self.W_hy(hidden_state)\n",
        "        ##################################################################\n",
        "        #                         END OF YOUR CODE                       #\n",
        "        ##################################################################\n",
        "        # ÏïÑÎûò Ï£ºÏÑùÎèÑ Ìï¥Ï†úÌïòÏÑ∏Ïöî.\n",
        "        return output, hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ePzKcHO--CoE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct!!!\n"
          ]
        }
      ],
      "source": [
        "model = CustomRNN(5, 6, 7)\n",
        "model_str = str(model).splitlines()\n",
        "import numpy\n",
        "stack = []\n",
        "for i in range(1, 4):\n",
        "    stack.append(int(model_str[i][29]))\n",
        "    stack.append(int(model_str[i][45]))\n",
        "\n",
        "prod = numpy.prod(stack)\n",
        "\n",
        "if prod == 45360:\n",
        "    print(\"Correct!!!\")\n",
        "else:\n",
        "    print(\"Incorrect...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oQPMObZT1Cvw",
        "Vow1djLS1ln9",
        "q69DoyMY11if",
        "bYkyU5yF16Bw",
        "lQVux07S2LlN",
        "HsBNZmn72has",
        "39856I6b2rna",
        "f_Na3v8B3L2Q",
        "FPqcB6qq3WhR",
        "O37RYi4v3a_c"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
