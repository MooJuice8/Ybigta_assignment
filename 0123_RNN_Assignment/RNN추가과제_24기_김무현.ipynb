{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmJ-t9b50PiK"
      },
      "source": [
        "##Text Generation using RNN LSTM (Pytorch)\n",
        "###Lyrics generatator  \n",
        "ğŸ¤– LSTM, GRUì— ëŒ€í•´ í•œêµ­ì–´ë¡œ ë” ì˜ ì•Œê³  ì‹¶ë‹¤ë©´  \n",
        "https://velog.io/@hipjaengyi_cat18/RNNRecurrent-Neural-Networkê³¼-LSTM-GPUë¥¼-ì´í•´í•´ë³´ì-ë‚´ê°€ë³´ë ¤ê³ ì •ë¦¬í•œAI  \n",
        "ğŸ¤– ì°¸ê³ í•œ ì½”ë“œ  \n",
        "https://github.com/trekhleb/machine-learning-experiments/tree/0cfc7cac2daaff3e37b33bbf1284d3f19a5d78a1/experiments/text_generation_shakespeare_rnn   \n",
        "https://www.kaggle.com/code/super13579/let-s-auto-write-the-deep-purple-lysics-pytorch/notebook#Let's-use-the-Deep-Purple-lysics-to-train-a-LSTM-simulated-Deep-Purple-write-lyrics-automatically-(Rock!!)   \n",
        "& special thanks to DS 22ê¸° ì¡°ì„±ì›  \n",
        "ğŸ¤– ë°ì´í„°ì…‹   \n",
        "from kaggle  \n",
        "ğŸ¤– LSTM ë…¼ë¬¸  \n",
        "https://www.bioinf.jku.at/publications/older/2604.pdf  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGPRHPzB089b"
      },
      "source": [
        "##I. INTRODUCTION  \n",
        "Implementing a Recurrent Neural Network (RNN), specifically Long-Short Term Memory (LSTM), to create a lyrics generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQPMObZT1Cvw"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aUafOKUy1Ezw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MoohyeonKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform\n",
        "import time\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjSB9AyB1Imb"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dt9XuA_1KLX"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_i-KTLK21M8x"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>artist</th>\n",
              "      <th>seq</th>\n",
              "      <th>song</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>No, no\\r\\nI ain't ever trapped out the bando\\r...</td>\n",
              "      <td>Everyday</td>\n",
              "      <td>0.626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>The drinks go down and smoke goes up, I feel m...</td>\n",
              "      <td>Live Till We Die</td>\n",
              "      <td>0.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>She don't live on planet Earth no more\\r\\nShe ...</td>\n",
              "      <td>The Otherside</td>\n",
              "      <td>0.240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>Trippin' off that Grigio, mobbin', lights low\\...</td>\n",
              "      <td>Pinot</td>\n",
              "      <td>0.536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Elijah Blake</td>\n",
              "      <td>I see a midnight panther, so gallant and so br...</td>\n",
              "      <td>Shadows &amp; Diamonds</td>\n",
              "      <td>0.371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        artist  \\\n",
              "0           0  Elijah Blake   \n",
              "1           1  Elijah Blake   \n",
              "2           2  Elijah Blake   \n",
              "3           3  Elijah Blake   \n",
              "4           4  Elijah Blake   \n",
              "\n",
              "                                                 seq                song  \\\n",
              "0  No, no\\r\\nI ain't ever trapped out the bando\\r...            Everyday   \n",
              "1  The drinks go down and smoke goes up, I feel m...    Live Till We Die   \n",
              "2  She don't live on planet Earth no more\\r\\nShe ...       The Otherside   \n",
              "3  Trippin' off that Grigio, mobbin', lights low\\...               Pinot   \n",
              "4  I see a midnight panther, so gallant and so br...  Shadows & Diamonds   \n",
              "\n",
              "   label  \n",
              "0  0.626  \n",
              "1  0.630  \n",
              "2  0.240  \n",
              "3  0.536  \n",
              "4  0.371  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ë“œë¼ì´ë¸Œì— ìˆëŠ” CSV íŒŒì¼ ì½ê¸° ì˜ˆì‹œ (lyrics.csvê°€ ìˆëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì ì–´ì£¼ì„¸ìš”)\n",
        "#file_path = '/content/drive/MyDrive/íŒŒì¼ê²½ë¡œ../lyrics.csv'\n",
        "#df = pd.read_csv(file_path)\n",
        "df = pd.read_csv('lyrics.csv')\n",
        "# data frame í™•ì¸\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b5Rbh1er1eUG"
      },
      "outputs": [],
      "source": [
        "#ë°ì´í„° ì¤‘ ì¼ë¶€ë§Œ ê°€ì ¸ì˜¤ê¸° - ê°€ì ¸ì˜¬ ë°ì´í„° ììœ ë¡­ê²Œ ì„ íƒí•´ì£¼ì„¸ìš”\n",
        "random_sample = df.sample(n=1000, random_state=19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gRPn3gdD1gbP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0              artist  \\\n",
            "67830        67830             Darkane   \n",
            "114589      114589              Kemuri   \n",
            "111513      111513                Them   \n",
            "98856        98856  Hank Williams, Jr.   \n",
            "23427        23427   The Panic Channel   \n",
            "\n",
            "                                                      seq  \\\n",
            "67830   The beauty of your escaping soul\\r\\nBehold my ...   \n",
            "114589  Are we still the same?\\r\\nOr are we so differe...   \n",
            "111513  Well, I love you, love you darlin'\\r\\nLike I n...   \n",
            "98856   Mr Weather man what is your forecast,\\r\\nI nee...   \n",
            "23427   I'm silent\\r\\nIn the rolling wake\\r\\nOf lucky ...   \n",
            "\n",
            "                       song   label  \n",
            "67830   Chase for Existence  0.0614  \n",
            "114589        Second Chance  0.8120  \n",
            "111513       All for Myself  0.8080  \n",
            "98856            Weatherman  0.3630  \n",
            "23427              Outsider  0.1650  \n"
          ]
        }
      ],
      "source": [
        "#ê°€ì ¸ì˜¨ ë°ì´í„° í™•ì¸\n",
        "print(random_sample.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vow1djLS1ln9"
      },
      "source": [
        "##Analyze the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4fAjivU91r5U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the beauty of your escaping soul\n",
            "behold my true distress\n",
            "your naked mind is barely existing\n",
            "corpus length: 1143721\n"
          ]
        }
      ],
      "source": [
        "#ë°ì´í„°í”„ë ˆì„ì—ì„œ 'seq' ì—´(ê°€ì‚¬ë¶€ë¶„)ì„ ì„ íƒí•˜ê³ , ê° í–‰ì˜ 'seq' ê°’ì„ ì†Œë¬¸ìë¡œ ë³€í™˜\n",
        "random_text = random_sample['seq'].str.cat(sep='\\n').lower()\n",
        "print(random_text[:94])\n",
        "print('corpus length:', len(random_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jF-v-1nQ1t02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the beauty of your escaping soul\n",
            "behold my true distress\n",
            "your naked mind is barely existing\n",
            "i have dreams you could never imagine\n",
            "explore your forbidden defiance\n",
            "see the realm of temptation\n",
            "knowing anger\n",
            "will betray me\n",
            "disconnected\n",
            "from all feelings\n",
            "the chase for my existence\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 286 characters in text.\n",
        "print(random_text[:286])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bzsxEKR71xR1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63 unique characters\n",
            "vocab: ['\\t', '\\n', '\\r', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '>', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file í™•ì¸\n",
        "vocab = sorted(set(random_text))\n",
        "\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "print('vocab:', vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q69DoyMY11if"
      },
      "source": [
        "##Process the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkyU5yF16Bw"
      },
      "source": [
        "###Vectorize the text\n",
        "Recurrent Neural Network (RNN)ì— í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ì œê³µí•˜ê¸° ì „ì—, í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì˜ ì‹œí€€ìŠ¤ì—ì„œ ìˆ«ìì˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I8a2MQBL14tm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\t':   0,\n",
            "  '\\n':   1,\n",
            "  '\\r':   2,\n",
            "  ' ' :   3,\n",
            "  '!' :   4,\n",
            "  '\"' :   5,\n",
            "  '#' :   6,\n",
            "  '%' :   7,\n",
            "  '&' :   8,\n",
            "  \"'\" :   9,\n",
            "  '(' :  10,\n",
            "  ')' :  11,\n",
            "  '*' :  12,\n",
            "  '+' :  13,\n",
            "  ',' :  14,\n",
            "  '-' :  15,\n",
            "  '.' :  16,\n",
            "  '/' :  17,\n",
            "  '0' :  18,\n",
            "  '1' :  19,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "char2index = {char: index for index, char in enumerate(vocab)}\n",
        "\n",
        "print('{')\n",
        "for char, _ in zip(char2index, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2index[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2O3TA1Bq2BF5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\t' '\\n' '\\r' ' ' '!' '\"' '#' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.'\n",
            " '/' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '>' '?' '[' ']' '`'\n",
            " 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '{' '}']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Map character indices to characters from vacabulary.\n",
        "index2char = np.array(vocab)\n",
        "print(index2char)\n",
        "\n",
        "len(index2char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nSFDK8un2EQg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text_as_int length: 1143721\n",
            "'the beauty of your escaping soul' --> array([54, 42, 39,  3, 36, 39, 35, 55, 54, 59,  3, 49, 40,  3, 59, 49, 55,\n",
            "       52,  3, 39, 53, 37, 35, 50, 43, 48, 41,  3, 53, 49, 55, 46])\n"
          ]
        }
      ],
      "source": [
        "# Convert chars in text to indices.\n",
        "text_as_int = np.array([char2index[char] for char in random_text])\n",
        "\n",
        "print('text_as_int length: {}'.format(len(text_as_int)))\n",
        "print('{} --> {}'.format(repr(random_text[:32]), repr(text_as_int[:32])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQVux07S2LlN"
      },
      "source": [
        "## Create training sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nmSyEX0F2OG2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence Window\n",
            "['the beauty of your escaping soul\\r\\nbehold my true d', 'he beauty of your escaping soul\\r\\nbehold my true di', 'e beauty of your escaping soul\\r\\nbehold my true dis', ' beauty of your escaping soul\\r\\nbehold my true dist', 'beauty of your escaping soul\\r\\nbehold my true distr']\n",
            "Target charaters\n",
            "['i' 's' 't' 'r' 'e']\n",
            "Number of sequences: 1143671\n"
          ]
        }
      ],
      "source": [
        "seq_length = 50\n",
        "step = 1\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(random_text) - seq_length, step):\n",
        "  sentences.append(random_text[i:i+seq_length])\n",
        "  next_chars.append(random_text[i+seq_length]) #Next character\n",
        "\n",
        "senteces = np.array(sentences)\n",
        "next_chars= np.array(next_chars)\n",
        "\n",
        "\n",
        "#Print Sentence Window and next charaters\n",
        "print('Sentence Window')\n",
        "print (sentences[:5])\n",
        "print('Target charaters')\n",
        "print (next_chars[:5])\n",
        "print('Number of sequences:', len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "i9OxqoOQ2Sq_"
      },
      "outputs": [],
      "source": [
        "def getdata(sentences, next_chars):\n",
        "    X = np.zeros((len(sentences),seq_length))\n",
        "    y = np.zeros((len(sentences)))\n",
        "    length = len(sentences)\n",
        "    index = 0\n",
        "    for i in range(len(sentences)):\n",
        "        sentence = sentences[i]\n",
        "        for t, char in enumerate(sentence):\n",
        "            X[i, t] = char2index[char]\n",
        "        y[i] = char2index[next_chars[i]]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V1F2Nb9b2UlX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training_x: (1143671, 50)\n",
            "Shape of training_y: (1143671,)\n"
          ]
        }
      ],
      "source": [
        "train_x,train_y = getdata(sentences, next_chars)\n",
        "print('Shape of training_x:', train_x.shape)\n",
        "print('Shape of training_y:', train_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYsqkk1Z2aMT"
      },
      "source": [
        "##Build the Model(Pytorch)\n",
        "## ì¶”ê³¼ ê³¼ì œ 1 : ì•„ë˜ ë¹ˆ ê³³ì„ ì±„ì›Œì£¼ì„¸ìš”!\n",
        "- Embedding layer : transfer index to embedding vector\n",
        "- Simple LSTM + dropout : Sequence data to hidden states , dropout for prevent overfitting\n",
        "- Fully connection layer : linear tranfer to a n_vocab vector to be output layer.  \n",
        "we don't need to do softmax here, we will do it when we calculate loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9-izwsvq2bMS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Simple_LSTM(nn.Module):\n",
        "    def __init__(self,n_vocab,hidden_dim, embedding_dim,dropout = 0.2):\n",
        "        super(Simple_LSTM, self).__init__()\n",
        "        ##################################################################\n",
        "        # TODO: ì£¼ì„, ________ ë¶€ë¶„ ì§€ìš°ê³  ë‹µì•ˆ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "        #\n",
        "        # Hint: ìœ„ì— embedding layer, simple LSTM + dropout, fully connected layer ì„¤ëª… ë¶€ë¶„ì„ ì½ê³  ì±„ì›Œì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "        #\n",
        "        ##################################################################\n",
        "        # ì•„ë˜ ì£¼ì„ í•´ì œ í›„ ì •ì˜í•´ì£¼ì„¸ìš”.\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim \n",
        "        self.lstm = nn.LSTM(hidden_dim, embedding_dim, dropout = dropout, num_layers = 2)\n",
        "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
        "        ##################################################################\n",
        "        #                         END OF YOUR CODE                       #\n",
        "        ##################################################################\n",
        "\n",
        "    def forward(self, seq_in):\n",
        "        # for LSTM, input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
        "        embedded = self.embeddings(seq_in.t())\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        # Only need to keep the last character\n",
        "        ht=lstm_out[-1]\n",
        "        out = self.fc(ht)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsBNZmn72has"
      },
      "source": [
        "## Create DataLoader of mini-batch training\n",
        "Use GPU to training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oxniKXkX2kMY"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mcuda()\n",
            "File \u001b[1;32mc:\\Users\\MoohyeonKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:289\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m     )\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m     )\n",
            "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "X_train_tensor = torch.tensor(train_x, dtype=torch.long).cuda()\n",
        "Y_train_tensor = torch.tensor(train_y, dtype=torch.long).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHQTDkkI2m_X"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "train = torch.utils.data.TensorDataset(X_train_tensor,Y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = 32) #batch_size ììœ ë¡­ê²Œ ë°”ê¿”ì£¼ì„¸ìš”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39856I6b2rna"
      },
      "source": [
        "##Start training\n",
        "- Hidden_size : 256\n",
        "- Embedding_size : 256\n",
        "- Use Adam optimizer(ë³€ê²½ ê°€ëŠ¥)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lctdA0O52tYl"
      },
      "outputs": [],
      "source": [
        "model = Simple_LSTM(63,256,256)\n",
        "model.cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002) # optimizer ììœ ë¡­ê²Œ ë°”ê¿”ì£¼ì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCyrqWdB21Cf"
      },
      "outputs": [],
      "source": [
        "import time # Add time counter\n",
        "avg_losses_f = []\n",
        "n_epochs=10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    avg_loss = 0.\n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        y_pred = model(x_batch)\n",
        "\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        avg_loss+= loss.item()/len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t time={:.2f}s'.format(\n",
        "        epoch + 1, n_epochs, avg_loss, elapsed_time))\n",
        "\n",
        "    avg_losses_f.append(avg_loss)\n",
        "\n",
        "print('All \\t loss={:.4f} \\t '.format(np.average(avg_losses_f)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Na3v8B3L2Q"
      },
      "source": [
        "##ê²°ê³¼ ë„ì‹í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIJh9gNm3M3e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(avg_losses_f)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPqcB6qq3WhR"
      },
      "source": [
        "##Create the function that can sample an index from a probability array\n",
        "- This function is to prevent the most likely chracter always be chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNTk5dkY3XV5"
      },
      "outputs": [],
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O37RYi4v3a_c"
      },
      "source": [
        "## Validate the model\n",
        "- Define the 50 start sentence legth (ì•ì— seq_lenth ë°”ê¾¸ë©´ sentence length ë°”ê¾¸ê¸° ê°€ëŠ¥)\n",
        "- Predict next char\n",
        "- Total create 400 characters lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsCmCcii3iJB"
      },
      "outputs": [],
      "source": [
        "# Define the start sentence\n",
        "sentence = 'i read in the book\\nthat the joyful man\\nplease kno'\n",
        "variance = 0.25\n",
        "generated = ''\n",
        "original = sentence\n",
        "window = sentence\n",
        "\n",
        "for i in range(400):\n",
        "    x = np.zeros((1, seq_length))\n",
        "    for t, char in enumerate(window):\n",
        "        x[0, t] = char2index[char] # Change the sentence to index vector shape (1,50)\n",
        "\n",
        "    x_in = Variable(torch.LongTensor(x).cuda())\n",
        "    pred = model(x_in)\n",
        "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
        "    next_index = sample(pred, variance)\n",
        "    next_char = index2char[next_index] # index to char\n",
        "\n",
        "    generated += next_char\n",
        "    window = window[1:] + next_char # Update Window for next char predict\n",
        "\n",
        "print(original + generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI5iJ0qr9nFd"
      },
      "source": [
        "ì¶”ê°€ê³¼ì œ -2\n",
        "## Pytorchë¡œ RNN êµ¬í˜„í•´ë³´ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smp0bv5T9KDV"
      },
      "source": [
        "## 1. RNN êµ¬í˜„\n",
        "Pytorchë¡œ neural network ëª¨ë¸ì„ êµ¬í˜„í•  ë•Œì—ëŠ” `nn.Module`ì„ ìƒì†ë°›ì•„ì„œ êµ¬í˜„í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "### [ì°¸ê³ ] ê°ì²´ì§€í–¥ ê°œë…ì„ ì˜ ëª¨ë¥¸ë‹¤ë©´?\n",
        "ê°ì²´ì§€í–¥ ê°œë…ì„ ì˜ ëª¨ë¥´ì‹ ë‹¤ë©´ <b>ìƒì†</b>ì´ë€ ìƒì†ì„ ë°›ì€ í´ë˜ìŠ¤ (ì—¬ê¸°ì„œëŠ” CustomRNN)ê°€ ë¶€ëª¨ í´ë˜ìŠ¤ (`nn.Module`)ì˜ ë©¤ë²„ ë³€ìˆ˜ì™€ ë©”ì†Œë“œë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê²¨ë°›ì•„ í•„ìš”ì— ë§ê²Œ ì¬ì •ì˜í•˜ê±°ë‚˜ ê¸°íƒ€ í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì„ ì¶”ê°€í•´ì„œ ì‚¬ìš©í•˜ëŠ” í–‰ìœ„ë¡œ ì‰½ê²Œ ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì½”ë“œì˜ ì¤‘ë³µë„ë¥¼ ë‚®ì¶”ê³  ë³´ë‹¤ íš¨ìœ¨ì ì¸ ì„¤ê³„ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´ì„œ `nn.Module` í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ë§Œë“  ëª¨ë“  í´ë˜ìŠ¤ë“¤ì€ `__init()__` ìƒì„±ìì™€ `forward()` ë©”ì†Œë“œë¥¼ êµ¬í˜„í•¨ìœ¼ë¡œì¨ ëª¨ë“  neural networkê°€ high levelì—ì„œëŠ” ë™ì¼í•œ ë™ì‘ì„ í•¨ì„ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë§Œì•½ ìƒì† ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ëª¨ë¸ì„ trainingí•˜ëŠ” ì½”ë“œ, inferenceë¥¼ í•˜ëŠ” ì½”ë“œ ë“±ì„ neural network ì¢…ë¥˜ë§ˆë‹¤ ìƒˆë¡œ ì§œì•¼ í•˜ë¯€ë¡œ ë³µì¡í•´ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "### êµ¬í˜„ ê´€ë ¨ ë°°ê²½ì§€ì‹\n",
        "`nn.Module` í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ìœ¼ë©´ `__init__()` ìƒì„±ìì™€ `forward()` ë©”ì†Œë“œë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤. ìƒì„±ìì—ì„œëŠ” ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  ê¸°ë³¸ì ì¸ ë©¤ë²„ ë³€ìˆ˜ë“¤ì„ ì´ˆê¸°í™”í•˜ê²Œ ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ë©¤ë²„ ë³€ìˆ˜ë¡œëŠ” í¬ê²Œ ë‘ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "1. ëª¨ë¸ ì•„í‚¤í…ì³ì™€ ê´€ë ¨ëœ dimensionë“¤ (ê°ê°ì˜ ì˜ë¯¸ëŠ” ë°œì œ PPT ì°¸ê³ )\n",
        " - Input vectorì˜ ê¸¸ì´\n",
        " - Hidden layerì˜ ê¸¸ì´\n",
        " - Output vectorì˜ ê¸¸ì´\n",
        " - Batch size\n",
        "\n",
        "\n",
        "2. ëª¨ë¸ì—ì„œ ì‚¬ìš©ë  layerë“¤\n",
        " - Pytorchì˜ `nn` moduleì—ì„œëŠ” neural networkì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‹¤ì–‘í•œ layerë¥¼ ë¯¸ë¦¬ êµ¬í˜„í•´ ë‘ì—ˆìŠµë‹ˆë‹¤. Convolution layer, pooling layer, linear layer ë“±ì´ ì •ì˜ë˜ì–´ ìˆì–´ì„œ ë³µì¡í•œ ì—°ì‚°ì„ ì§ì ‘ êµ¬í˜„í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ë³¸ ê³¼ì œì—ì„œëŠ” í•´ë‹¹ layerë¥¼ ìŒ“ì•„ì„œ RNNì„ êµ¬í˜„í•œë‹¤ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        " - ë³¸ ê³¼ì œì—ì„œëŠ” Linear layerë§Œ í™œìš©í•˜ë©´ ë©ë‹ˆë‹¤. ì´ëŠ” MLP ì„¸ì…˜ì—ì„œ ë°°ìš´ fully connected layerì™€ ê°™ìŠµë‹ˆë‹¤. FC layerì´ë¯€ë¡œ input, outputì˜ sizeì™€ bias ì‚¬ìš© ìœ ë¬´ë§Œ ì •ì˜í•´ì£¼ë©´ ë©ë‹ˆë‹¤. https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "\n",
        "ìƒì„±ìë¥¼ ì •ì˜í–ˆìœ¼ë©´ `forward()` í•¨ìˆ˜ë¥¼ ì •ì˜í•  ì°¨ë¡€ì…ë‹ˆë‹¤. `forward()` ë©”ì†Œë“œê°€ ëª¨ë¸ êµ¬í˜„ì—ì„œ í•µì‹¬ì…ë‹ˆë‹¤. ì´ ë©”ì†Œë“œëŠ” ëª¨ë¸ì— input dataë¥¼ ì§‘ì–´ë„£ìœ¼ë©´ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ê³  argumentë¡œ inputì´ ì „ë‹¬ë©ë‹ˆë‹¤. ì•ì„œ ì •ì˜í•œ layerë“¤ì„ ì˜ í˜¸ì¶œí•´ì„œ ë©”ì†Œë“œë¥¼ êµ¬í˜„í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "*Backward passëŠ” ëª¨ë¸ trainì„ í•  ë•Œ `backward()`ê°€ ì•Œì•„ì„œ í•´ì£¼ê¸° ë•Œë¬¸ì— `forward()`ë§Œ ì •ì˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dDbl35zl95nQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N2YsSoYG98Lh"
      },
      "outputs": [],
      "source": [
        "# nn.Moduleì„ ìƒì†ë°›ì•„ì„œ CustomRNN class ì •ì˜\n",
        "\n",
        "class CustomRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN basic block\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        input_size: Input vector ê¸¸ì´\n",
        "        hidden_size: Hidden state vector ê¸¸ì´\n",
        "        output_size: Output vector ê¸¸ì´\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.W_xh = nn.Linear(input_size, hidden_size, bias=False)\n",
        "        ##################################################################\n",
        "        # TODO: í•„ìš”í•œ ë©¤ë²„ ë³€ìˆ˜ 2ê°œë¥¼ ì¶”ê°€ë¡œ ì •ì˜í•˜ì„¸ìš”.\n",
        "        #\n",
        "        # 1. W_hh: hidden layer vectorì— ê³±í•´ì§€ëŠ” weight\n",
        "        # 2. W_hy: hidden layerë¡œ outputì„ ìƒì„±í•  ë•Œ ê³±í•´ì§€ëŠ” weight\n",
        "        #\n",
        "        # Hint: ìœ„ì˜ self.W_xh ì½”ë“œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.\n",
        "        #\n",
        "        ##################################################################\n",
        "        # ì•„ë˜ ì£¼ì„ í•´ì œ í›„ ì •ì˜í•˜ì‹œë©´ ë©ë‹ˆë‹¤. biasëŠ” ë‘˜ ë‹¤ Trueë¡œ í•´ì£¼ì„¸ìš”.\n",
        "        self.W_hh = nn.Linear(hidden_size, hidden_size, bias=True)  \n",
        "        self.W_hy = nn.Linear(hidden_size, output_size, bias=True)\n",
        "        ##################################################################\n",
        "        #                         END OF YOUR CODE                       #\n",
        "        ##################################################################\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        W_xh_x = self.W_xh(x)  # W_xh weightì— input xë¥¼ ê³±í•´ì¤€ ê²°ê³¼\n",
        "        ##################################################################\n",
        "        # TODO: Forward passë¥¼ ê³„ì‚°í•˜ëŠ” ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n",
        "        #\n",
        "        ########################### ì „ì²´ ê³¼ì • ##############################\n",
        "        #\n",
        "        # 1. W_xhì™€ inputì„ ê³±í•œë‹¤.\n",
        "        # 2. W_hhì™€ {t - 1} ì‹œì ì—ì„œì˜ hidden state vectorë¥¼ ê³±í•œë‹¤.\n",
        "        # 3. ë‘˜ì´ ë”í•œë‹¤.\n",
        "        # 4. tanhë¥¼ í†µê³¼ì‹œì¼œì„œ ìƒˆë¡œìš´ hidden stateë¥¼ ë§Œë“¤ì–´ë‚¸ë‹¤.\n",
        "        # 5. W_hyì™€ ìƒˆë¡œìš´ hidden stateë¥¼ ê³±í•´ì„œ outputì„ ë§Œë“¤ì–´ë‚¸ë‹¤.\n",
        "        # 6. outputê³¼ ìƒˆë¡œìš´ hidden stateë¥¼ returní•œë‹¤.\n",
        "        #\n",
        "        # Hint: torch.tanh\n",
        "        #\n",
        "        ##################################################################\n",
        "        # ì•„ë˜ ì£¼ì„ í•´ì œ í›„ ì¶”ê°€í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
        "        W_hh_x = self.W_hh(hidden_state)\n",
        "        hidden_state = torch.tanh(W_xh_x + W_hh_x)\n",
        "        output = self.W_hy(hidden_state)\n",
        "        ##################################################################\n",
        "        #                         END OF YOUR CODE                       #\n",
        "        ##################################################################\n",
        "        # ì•„ë˜ ì£¼ì„ë„ í•´ì œí•˜ì„¸ìš”.\n",
        "        return output, hidden_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ePzKcHO--CoE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correct!!!\n"
          ]
        }
      ],
      "source": [
        "model = CustomRNN(5, 6, 7)\n",
        "model_str = str(model).splitlines()\n",
        "import numpy\n",
        "stack = []\n",
        "for i in range(1, 4):\n",
        "    stack.append(int(model_str[i][29]))\n",
        "    stack.append(int(model_str[i][45]))\n",
        "\n",
        "prod = numpy.prod(stack)\n",
        "\n",
        "if prod == 45360:\n",
        "    print(\"Correct!!!\")\n",
        "else:\n",
        "    print(\"Incorrect...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oQPMObZT1Cvw",
        "Vow1djLS1ln9",
        "q69DoyMY11if",
        "bYkyU5yF16Bw",
        "lQVux07S2LlN",
        "HsBNZmn72has",
        "39856I6b2rna",
        "f_Na3v8B3L2Q",
        "FPqcB6qq3WhR",
        "O37RYi4v3a_c"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
